# A code for multiple random forest models with a sliding window approach to create class imbalance, no augmentation
# Load and balance the dataset with equal samples from both groups
# Configure iteration parameters for progressively reducing group A training data
# Loop through 185 configurations with decreasing group A size
# Balance training data using ROSE to address class imbalance  
# Train a Random Forest classifier on each training set
# Record feature importance for all features and top 10 most important features per iteration
# Predict on test sets and compute confusion matrices
# Calculate AUC scores from ROC analysis on test predictions
# Compile results including accuracy, precision, recall, and F1-score
# Save all results and feature importance metrics to Excel files

library(dplyr)
library(tidyr)
library(openxlsx)
library(randomForest)
library(pROC)
library(ROSE)


# Select a file from those with different seeds
data_full <- read.xlsx("dataseed219.xlsx")

# Balance the dataset by taking 600 samples from each group
data <- data_full %>% group_by(group) %>% slice_head(n = 600) %>% ungroup()

# Initialize empty dataframes to store outputs
all_results <- data.frame()
model_importance <- data.frame()
top10_importance <- data.frame()

# Configuration settings for sampling and iterations
initial_size <- 600              # Initial sample size for each group
step_size <- 3                   # Step size for decreasing group A size per iteration
num_configs <- 185               # Total number of iterations/configurations
initial_test_A_size <- 200       # Initial test size for group A
initial_test_B_size <- 200       # Test size for group B remains constant
fixed_group_B_size <- 600        # Fixed size for group B sampling pool

# Identify indices of group A and group B in the dataset
group_A_indices <- which(data$group == "A")
group_B_indices <- which(data$group == "B")

# Iterate over each configuration
for (idx in seq_len(num_configs)) {
    set.seed(123 + idx)  # Ensure reproducibility with varying seeds
    
    # Dynamically reduce test size for group A as iteration progresses
    group_A_test_size <- initial_test_A_size - (idx - 1)
    group_B_test_size <- initial_test_B_size
    
    # Create training and test sets for group A
    group_A_train <- sample(group_A_indices, size = floor(2/3 * (initial_size - (idx - 1) * step_size)))
    remaining_A <- setdiff(group_A_indices, group_A_train)
    group_A_test <- if (length(remaining_A) < group_A_test_size) remaining_A else remaining_A[1:group_A_test_size]
    
    # Create training and test sets for group B
    group_B_subset <- group_B_indices[1:fixed_group_B_size]
    group_B_train <- sample(group_B_subset, size = floor(2/3 * fixed_group_B_size))
    group_B_test <- setdiff(group_B_subset, group_B_train)[1:group_B_test_size]
    
    # Combine training and test indices
    train_indices <- c(group_A_train, group_B_train)
    test_indices <- c(group_A_test, group_B_test)
    
    # Create training and test data
    train_data <- data[train_indices, ]
    test_data <- data[test_indices, ]
    
    # Convert group labels to binary: 0 = A, 1 = B
    train_data$group <- as.numeric(train_data$group == "B")
    test_data$group <- as.numeric(test_data$group == "B")
    
    # Apply ROSE only after the first iteration to generate synthetic samples
    if (idx > 1) {
        num_synthetic_needed_A <- length(group_B_train)
        num_synthetic_needed_B <- length(group_B_train)
        total_synthetic_needed <- num_synthetic_needed_A + num_synthetic_needed_B
        
        # Generate balanced synthetic data using ROSE
        rose_output <- ROSE(group ~ ., data = train_data, N = total_synthetic_needed * 3, p = 0.7, seed = sample.int(1e5, 1))$data
        rose_output$group <- as.numeric(rose_output$group)
        
        # Separate and sample synthetic data for A and B
        rose_output_A <- rose_output[rose_output$group == 0, ]
        rose_output_B <- rose_output[rose_output$group == 1, ]
        
        rose_output_A_selected <- rose_output_A[sample(nrow(rose_output_A), min(nrow(rose_output_A), num_synthetic_needed_A)), ]
        rose_output_B_selected <- rose_output_B[sample(nrow(rose_output_B), min(nrow(rose_output_B), num_synthetic_needed_B)), ]
        
        # Combine balanced synthetic training set
        train_data <- rbind(rose_output_A_selected, rose_output_B_selected)
    }
    
    # Convert back to factor format for modeling
    train_data$group <- factor(train_data$group, levels = c(0, 1), labels = c("A", "B"))
    test_data$group <- factor(test_data$group, levels = c(0, 1), labels = c("A", "B"))
    
    # Train Random Forest model
    rf_model <- randomForest(
        group ~ ., 
        data = train_data, 
        ntree = 500, 
        importance = TRUE, 
        classwt = c(A = 1, B = 3)  # Weight class B higher due to imbalance
    )
    
    # Extract and store variable importance scores
    importance_scores <- importance(rf_model)
    importance_df <- data.frame(
        Feature = rownames(importance_scores),
        Importance = importance_scores[, "MeanDecreaseGini"],
        Iteration = idx
    )
    model_importance <- bind_rows(model_importance, importance_df)
    
    # Get top 10 features by importance for this iteration
    top10 <- importance_df %>% 
        arrange(desc(Importance)) %>% 
        head(10)
    top10$Iteration <- idx
    top10_importance <- bind_rows(top10_importance, top10)
    
    # Predict on the test data
    test_probabilities <- predict(rf_model, newdata = test_data, type = "prob")[, "B"]
    test_predictions <- predict(rf_model, newdata = test_data)
    
    # Build test confusion matrix
    test_conf_matrix <- table(Predicted = test_predictions, Actual = test_data$group)
    
    # Extract confusion matrix components safely
    conf_values_test <- c(
        ifelse("A" %in% rownames(test_conf_matrix) && "A" %in% colnames(test_conf_matrix), test_conf_matrix["A", "A"], 0),
        ifelse("B" %in% rownames(test_conf_matrix) && "A" %in% colnames(test_conf_matrix), test_conf_matrix["B", "A"], 0),
        ifelse("A" %in% rownames(test_conf_matrix) && "B" %in% colnames(test_conf_matrix), test_conf_matrix["A", "B"], 0),
        ifelse("B" %in% rownames(test_conf_matrix) && "B" %in% colnames(test_conf_matrix), test_conf_matrix["B", "B"], 0)
    )
    
    # Compute AUC for test set
    roc_obj <- roc(test_data$group, test_probabilities)
    auc_test <- as.numeric(auc(roc_obj))
    
    # Record all key metrics for this iteration
    iteration_results <- data.frame(
        iteration = idx,
        auc_test = auc_test,
        test_cm_A_A = conf_values_test[1],
        test_cm_A_B = conf_values_test[2],
        test_cm_B_A = conf_values_test[3],
        test_cm_B_B = conf_values_test[4],
        group_A_train = length(group_A_train),
        group_B_train = length(group_B_train),
        total_test_A = length(group_A_test),
        total_test_B = length(group_B_test)
    )
    all_results <- bind_rows(all_results, iteration_results)
}

# Add evaluation metrics to the results
all_results <- all_results %>%
    mutate(
        accuracy_test = (test_cm_A_A + test_cm_B_B) / (test_cm_A_A + test_cm_A_B + test_cm_B_A + test_cm_B_B),
        precision_test = test_cm_A_A / (test_cm_A_A + test_cm_B_A),
        recall_test = test_cm_A_A / (test_cm_A_A + test_cm_A_B),
        f1_score_test = 2 * (precision_test * recall_test) / (precision_test + recall_test)
    )

# Compute class proportions and prediction accuracy percentages
all_results$Percent_A_to_all <- round(100 * (all_results$group_A_train + all_results$total_test_A) /
                                          (all_results$group_A_train + all_results$group_B_train +
                                               all_results$total_test_A + all_results$total_test_B), 1)
all_results$Percent_true_A <- round(100 * all_results$test_cm_A_A / all_results$total_test_A, 1)
all_results$Percent_true_B <- round(100 * all_results$test_cm_B_B / all_results$total_test_B, 1)

# Save results to Excel files
write.xlsx(all_results, "RF_results_ROSE_completeAB.xlsx")
write.xlsx(model_importance, "RF_model_importance_ROSE_completeAB.xlsx")
write.xlsx(top10_importance, "RF_top10_importance_ROSE_completeAB.xlsx")


# plotting
library(dplyr)
library(openxlsx)
library(ggplot2)
library(gridExtra)
library(ggplotify)

all_results <- read.xlsx("RF_results_ROSE_completeAB.xlsx")
model_coefficients <- read.xlsx("RF_model_Importance_ROSE_completeAB.xlsx")
top10_coefficients <- read.xlsx("RF_top10_importance_ROSE_completeAB.xlsx")


percent<-all_results[,c(1,15)]
colnames(percent)[1] <- "Iteration"

model_coefficients <- as.data.frame(full_join(model_coefficients, percent))

top10_coefficients <- as.data.frame(full_join(top10_coefficients, percent))

colnames(top10_coefficients)[2] <- "Coefficient"
colnames(model_coefficients)[2] <- "Coefficient"


# lineplots
xxx <- all_results

p1 <- ggplot(xxx, aes(x = Percent_A_to_all)) +
    geom_line(aes(y = Percent_true_A, color = "A"),  size = 0.3) +
    geom_line(aes(y = Percent_true_B, color = "B"), size = 0.3) +
    scale_color_manual(
        values = c("A" = "red", "B" = "blue"),
        labels = c("Group A", "Group B")
    ) +
    labs(x = "Percent of Group A in Total Data", 
         y = "Percent Correctly Identified Samples", 
         color = NULL,  # Suppress legend title
         title = "Random Forest on Gene Expression Data  \nBoth Groups Replaced with ROSE Synthetic Samples") +
    theme_classic() +
    theme(plot.title = element_text(hjust = 0.5, size = 10)) +
    # Vertical dashed lines in purple that stop at Percent_true_A
    geom_segment(aes(x = 40, xend = 40, 
                     y = 0, 
                     yend = Percent_true_A[which.min(abs(Percent_A_to_all - 40))]), 
                 linetype = "dashed", color = "purple", size = 0.2) +
    geom_segment(aes(x = 45, xend = 45, 
                     y = 0, 
                     yend = Percent_true_A[which.min(abs(Percent_A_to_all - 45))]), 
                 linetype = "dashed", color = "purple", size = 0.2) +
    geom_segment(aes(x = 50, xend = 50, 
                     y = 0, 
                     yend = Percent_true_A[which.min(abs(Percent_A_to_all - 50))]), 
                 linetype = "dashed", color = "purple", size = 0.2) +
    # Horizontal dashed lines in purple from y-axis to the intersection points
    geom_segment(aes(x = 0, xend = 40, 
                     y = Percent_true_A[which.min(abs(Percent_A_to_all - 40))], 
                     yend = Percent_true_A[which.min(abs(Percent_A_to_all - 40))]),
                 linetype = "dashed", color = "purple", size = 0.2) +
    geom_segment(aes(x = 0, xend = 45, 
                     y = Percent_true_A[which.min(abs(Percent_A_to_all - 45))], 
                     yend = Percent_true_A[which.min(abs(Percent_A_to_all - 45))]),
                 linetype = "dashed", color = "purple", size = 0.2) +
    geom_segment(aes(x = 0, xend = 50, 
                     y = Percent_true_A[which.min(abs(Percent_A_to_all - 50))], 
                     yend = Percent_true_A[which.min(abs(Percent_A_to_all - 50))]),
                 linetype = "dashed", color = "purple", size = 0.2)


t1 <- ggplot(xxx, aes(x = Percent_A_to_all)) +
    geom_line(aes(y = accuracy_test, color = "accuracy_test"), size = 0.3) +
    geom_line(aes(y = precision_test, color = "precision_test"), size = 0.3) +
    geom_line(aes(y = recall_test, color = "recall_test"), size = 0.3) +
    geom_line(aes(y = f1_score_test, color = "f1_score_test"), size = 0.3) +
    geom_line(aes(y = auc_test, color = "auc_test"), , size = 0.3) +
    scale_color_manual(values = c("accuracy_test" = "blue", 
                                  "precision_test" = "red", 
                                  "recall_test" = "green", 
                                  "f1_score_test" = "purple", 
                                  "auc_test" = "orange"),
                       labels = c("Accuracy", "AUC", "f1 Score", "Precision", "Recall")
    ) +
    ylim(0, NA) +  
    theme_classic() +
    theme(plot.title = element_text(hjust = 0.5, size = 10)) +
    labs(x = "Percent of Group A in Total Data", 
         y = "", 
         color = NULL, 
         title = "Random Forest on Gene Expression Data  \nBoth Groups Replaced with ROSE Synthetic Samples") 

# Arrange the plots in a grid: 1 rows 2 columns
combined_plot <- grid.arrange(
    p1, t1,
    nrow = 1,
    ncol = 2
)

# Save the combined plot 
ggsave("RF_ROSE_GeneExp.png", combined_plot, width = 8.27, height = 3.6, units = "in")



# plot feature frequencies in a barplot

# Count occurrences of each Feature
feature_counts <- as.data.frame(table(top10_coefficients$Feature))
colnames(feature_counts) <- c("Feature", "Count")

# Keep only the top 12 features
top12_features <- feature_counts %>%
    arrange(desc(Count)) %>%
    slice_head(n = 12)

# Plot the feature frequency as a barplot
p <- ggplot(top12_features, aes(x = reorder(Feature, Count), y = Count, fill = Count)) +
    geom_bar(stat = "identity") +
    coord_flip() +  # Flip for better readability
    scale_fill_gradient(high = "#440154", low = "#FDE725") +  # Color gradient
    ylim(0, 185) +
    theme_minimal() +
    labs(title = "Top 12 Most Frequent Features, Random Forest on Gene Expression Data \nBoth Groups Replaced with ROSE Synthetic Samples",
         x = "Feature",
         y = "Count") +
    theme(
        axis.text.y = element_text(size = 7),
        plot.title = element_text(hjust = 0.5, size = 12),
        axis.title.x = element_text(size = 10),
        axis.title.y = element_text(size = 10)
    )

# Save the plot
ggsave("RF_ROSE_GeneExp_feature_frequency_barplot.png", p, width = 8.27, height = 2.8, dpi = 300, bg = "white")


# plot coefficients of top 5 most frequent features

# Count feature occurrences across all iterations
feature_counts <- table(unlist(top10_coefficients$Feature))

# Select the top 5 most frequent features
top_features <- names(sort(feature_counts, decreasing = TRUE))[1:5]

# Filter data for the selected top features and Percent_A_to_all >= 10%
filtered_data <- top10_coefficients %>%
    filter(Feature %in% top_features, Percent_A_to_all >= 10)

# Define breaks to reduce the number of labels for x-axis (Percent_A_to_all)
break_positions <- unique(filtered_data$Percent_A_to_all)[seq(1, length(unique(filtered_data$Percent_A_to_all)), length.out = 12)]

# Plot the coefficients against Percent_A_to_all
ggplot(filtered_data, aes(x = Percent_A_to_all, y = Coefficient, color = Feature, group = Feature)) + 
    geom_line(size = 1) + 
    geom_point(size = 2) +
    scale_color_manual(values = c("#1f77b4", "#ff7f0e", "#2ca02c", "#d62728", "#9467bd")) +  # Custom colors for distinction (5 colors)
    scale_x_continuous(breaks = break_positions, limits = c(min(filtered_data$Percent_A_to_all), max(filtered_data$Percent_A_to_all))) + # x-axis limits and breaks
    labs(x = "Percent of Group A in Total Data", y = "Coefficient", color = "Feature", title = "Top 5 Features; Random Forest \nBoth Groups Replaced with ROSE Synthetic Samples") +
    theme_minimal() +
    theme(
        plot.title = element_text(hjust = 0.5, size = 20),
        axis.text.x = element_text(angle = 90, hjust = 1),
        axis.title.x = element_text(size = 14),  # Increase size of x-axis label
        axis.title.y = element_text(size = 14)   # Increase size of y-axis label
    )

# Save the plot
ggsave("RF_ROSE_GeneExp_top5_coefficients_lineplot.png", width = 12, height = 5, dpi = 300, bg = "white")
